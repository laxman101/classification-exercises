{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482557a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# import splitting and imputing functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# import my acquire module\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efbc8c7",
   "metadata": {},
   "source": [
    "### Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f47384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_iris(iris_df):\n",
    "    '''\n",
    "    This function will clean the data...\n",
    "    '''\n",
    "    iris_df = iris_df.drop(columns='species_id')\n",
    "    iris_df.rename(columns={'species_name':'species'}, inplace=True)\n",
    "    dummy_df = pd.get_dummies(iris_df[['species']], dummy_na=False)\n",
    "    iris_df = pd.concat([iris_df, dummy_df], axis=1)\n",
    "    \n",
    "    return iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3790dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_iris_data(df):\n",
    "    '''\n",
    "    Takes in a dataframe and return train, validate, test subset dataframes\n",
    "    '''\n",
    "    train, test = train_test_split(iris_df, test_size = .2, random_state=123, stratify=iris_df.species)\n",
    "    train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.species)\n",
    "    \n",
    "    return train, validate, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d85c0",
   "metadata": {},
   "source": [
    "### Titanic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb8323f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_titanic(df):    \n",
    "    df.drop(columns=['passenger_id', 'class', 'embarked', 'deck'], axis=1, inplace=True)\n",
    "    df = pd.get_dummies(df, columns=[\"sex\", \"embark_town\"], drop_first=[True, True])\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce358cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(titanic_df):\n",
    "    '''\n",
    "    Takes in a dataframe and return train, validate, test subset dataframes\n",
    "    '''\n",
    "    train, test = train_test_split(titanic_df, test_size = .2, random_state=123, stratify=titanic_df.survived)\n",
    "    train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ba505",
   "metadata": {},
   "source": [
    "### Telco Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e10e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_telco(telco_df):\n",
    "    '''\n",
    "    This function will clean the telco data.\n",
    "    '''\n",
    "    telco_df = telco_df.drop_duplicates()\n",
    "    cols_to_drop = ['payment_type_id', 'internet_service_type_id', 'contract_type_id']\n",
    "    telco_df = telco_df.drop(columns=cols_to_drop)\n",
    "    dummy_df = pd.get_dummies(telco_df[['gender', 'contract_type', 'internet_service_type', 'payment_type']], dummy_na=False, drop_first=[True, True, True, True])\n",
    "    telco_df = pd.concat([telco_df, dummy_df], axis=1)\n",
    "    \n",
    "    return telco_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d762e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(telco_df):\n",
    "    '''\n",
    "    Takes in a dataframe and return train, validate, test subset dataframes\n",
    "    '''\n",
    "    train, test = train_test_split(telco_df, test_size = .2, random_state=17, stratify=telco_df.churn)\n",
    "    train, validate = train_test_split(train, test_size=.3, random_state=17, stratify=train.churn)\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7799a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_telco(telco_df):\n",
    "    '''\n",
    "    This function will clean the telco data...\n",
    "    '''\n",
    "    #Drop Duplicates\n",
    "    telco_df = telco_df.drop_duplicates()\n",
    "    \n",
    "    # Drop null values stored as whitespace    \n",
    "    telco_df['total_charges'] = telco_df['total_charges'].str.strip()\n",
    "    telco_df = telco_df[telco_df.total_charges != '']\n",
    "    \n",
    "    # Convert to correct datatype\n",
    "    telco_df['total_charges'] = telco_df.total_charges.astype(float)\n",
    "    \n",
    "    # Drop Columns\n",
    "    cols_to_drop = ['customer_id', 'payment_type_id', 'internet_service_type_id', 'contract_type_id']\n",
    "    telco_df = telco_df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Get dummies for non-binary categorical variables\n",
    "    dummy_df = pd.get_dummies(telco_df[['multiple_lines', \\\n",
    "                              'online_security', \\\n",
    "                              'online_backup', \\\n",
    "                              'device_protection', \\\n",
    "                              'tech_support', \\\n",
    "                              'streaming_tv', \\\n",
    "                              'streaming_movies', \\\n",
    "                              'contract_type', \\\n",
    "                              'internet_service_type', \\\n",
    "                              'payment_type']], dummy_na=False)\n",
    "    # Concatenate dummy dataframe to original \n",
    "    telco_df = pd.concat([telco_df, dummy_df], axis=1)\n",
    "   \n",
    "    return telco_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53492625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
